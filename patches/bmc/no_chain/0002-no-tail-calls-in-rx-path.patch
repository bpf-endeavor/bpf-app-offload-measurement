From 800e329dddccf43d6b04941b24befd7ae30b47e4 Mon Sep 17 00:00:00 2001
From: Farbod Shahinfar <fshahinfar1@gmail.com>
Date: Fri, 5 Jul 2024 17:27:11 +0000
Subject: [PATCH 2/3] no tail calls in rx path

---
 bmc/Makefile   |   3 +
 bmc/bmc_kern.c | 482 ++++++++++++++++++++++++-------------------------
 bmc/bmc_user.c |   8 +-
 3 files changed, 244 insertions(+), 249 deletions(-)

diff --git a/bmc/Makefile b/bmc/Makefile
index 6b6a8ec..9a4efe4 100644
--- a/bmc/Makefile
+++ b/bmc/Makefile
@@ -5,6 +5,9 @@ BPF_CFLAGS =
 
 default: bmc_kern.o bmc
 
+clean:
+	rm bmc bmc_kern.o
+
 bmc_kern.o: bmc_kern.c bmc_common.h
 	export CFLAGS="$(BPF_CFLAGS)" && bash $(BPF_COMPILE_SCRIPT) bmc_kern.c $@
 
diff --git a/bmc/bmc_kern.c b/bmc/bmc_kern.c
index c05a616..462c8d9 100644
--- a/bmc/bmc_kern.c
+++ b/bmc/bmc_kern.c
@@ -109,230 +109,85 @@ struct bpf_map_def SEC("maps") map_progs_tc = {
 
 static inline __u16 compute_ip_checksum(struct iphdr *ip)
 {
-    __u32 csum = 0;
-    __u16 *next_ip___u16 = (__u16 *)ip;
+	__u32 csum = 0;
+	__u16 *next_ip___u16 = (__u16 *)ip;
 
-    ip->check = 0;
+	ip->check = 0;
 
 #pragma clang loop unroll(full)
-    for (int i = 0; i < (sizeof(*ip) >> 1); i++) {
-        csum += *next_ip___u16++;
-    }
+	for (int i = 0; i < (sizeof(*ip) >> 1); i++) {
+		csum += *next_ip___u16++;
+	}
 
 	return ~((csum & 0xffff) + (csum >> 16));
 }
 
-SEC("bmc_rx_filter")
-int bmc_rx_filter_main(struct xdp_md *ctx)
+static inline int bmc_invalidate_cache_main(struct xdp_md *ctx)
 {
 	void *data_end = (void *)(long)ctx->data_end;
 	void *data = (void *)(long)ctx->data;
 	struct ethhdr *eth = data;
 	struct iphdr *ip = data + sizeof(*eth);
-	void *transp = data + sizeof(*eth) + sizeof(*ip);
-	struct udphdr *udp;
-	struct tcphdr *tcp;
-	char *payload;
-	__be16 dport;
-
-	if (ip + 1 > data_end)
-		return XDP_PASS;
-
-	switch (ip->protocol) {
-		case IPPROTO_UDP:
-			udp = (struct udphdr *) transp;
-			if (udp + 1 > data_end)
-				return XDP_PASS;
-			dport = udp->dest;
-			payload = transp + sizeof(*udp) + sizeof(struct memcached_udp_header);
-			break;
-		case IPPROTO_TCP:
-			tcp = (struct tcphdr *) transp;
-			if (tcp + 1 > data_end)
-				return XDP_PASS;
-			dport = tcp->dest;
-			payload = transp + sizeof(*tcp);
-			break;
-		default:
-			return XDP_PASS;
-	}
-
-	if (dport == bpf_htons(11211) && payload+4 <= data_end) {
-
-		if (ip->protocol == IPPROTO_UDP && payload[0] == 'g' && payload[1] == 'e' && payload[2] == 't' && payload[3] == ' ') { // is this a GET request
-			unsigned int zero = 0;
-			struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
-			if (!stats) {
-				return XDP_PASS;
-			}
-			stats->get_recv_count++;
-
-			struct parsing_context *pctx = bpf_map_lookup_elem(&map_parsing_context, &zero);
-			if (!pctx) {
-				return XDP_PASS;
-			}
-			pctx->key_count = 0;
-			pctx->current_key = 0;
-			pctx->write_pkt_offset = 0;
-
-			unsigned int off;
-#pragma clang loop unroll(disable)
-			for (off = 4; off < BMC_MAX_PACKET_LENGTH && payload+off+1 <= data_end && payload[off] == ' '; off++) {} // move offset to the start of the first key
-			if (off < BMC_MAX_PACKET_LENGTH) {
-				pctx->read_pkt_offset = off; // save offset
-				if (bpf_xdp_adjust_head(ctx, (int)(sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(struct memcached_udp_header) + off))) { // push headers + 'get ' keyword
-					return XDP_PASS;
-				}
-				bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_HASH_KEYS);
-			}
-		}
-		else if (ip->protocol == IPPROTO_TCP) {
-			bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_INVALIDATE_CACHE);
-		}
-	}
-
-	return XDP_PASS;
-}
-
-
-SEC("bmc_hash_keys")
-int bmc_hash_keys_main(struct xdp_md *ctx)
-{
-	void *data_end = (void *)(long)ctx->data_end;
-	void *data = (void *)(long)ctx->data;
-	char *payload = (char *) data;
+	struct tcphdr *tcp = data + sizeof(*eth) + sizeof(*ip);
+	char *payload = (char *) (tcp + 1);
 	unsigned int zero = 0;
 
 	if (payload >= data_end)
 		return XDP_PASS;
 
-	struct parsing_context *pctx = bpf_map_lookup_elem(&map_parsing_context, &zero);
-	if (!pctx) {
-		return XDP_PASS;
-	}
-
-	struct memcached_key *key = bpf_map_lookup_elem(&map_keys, &pctx->key_count);
-	if (!key) {
+	struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
+	if (!stats) {
 		return XDP_PASS;
 	}
-	key->hash = FNV_OFFSET_BASIS_32;
-
-	unsigned int off, done_parsing = 0, key_len = 0;
-
-	// compute the key hash
-#pragma clang loop unroll(disable)
-	for (off = 0; off < BMC_MAX_KEY_LENGTH+1 && payload+off+1 <= data_end; off++) {
-		if (payload[off] == '\r') {
-			done_parsing = 1;
-			break;
-		}
-		else if (payload[off] == ' ') {
-			break;
-		}
-		else if (payload[off] != ' ') {
-			key->hash ^= payload[off];
-			key->hash *= FNV_PRIME_32;
-			key_len++;
-		}
-	}
 
-	if (key_len == 0 || key_len > BMC_MAX_KEY_LENGTH) {
-		bpf_xdp_adjust_head(ctx, 0 - (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header) + pctx->read_pkt_offset)); // unexpected key, let the netstack handle it
-		return XDP_PASS;
-	}
+	__u32 hash;
+	int set_found = 0, key_found = 0;
 
-	__u32 cache_idx = key->hash % BMC_CACHE_ENTRY_COUNT;
-	struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
-	if (!entry) { // should never happen since cache map is of type BPF_MAP_TYPE_ARRAY
-		return XDP_PASS;
-	}
+	for (unsigned int off = 0; off < BMC_MAX_PACKET_LENGTH && payload+off+1 <= data_end; off++) {
 
-	bpf_spin_lock(&entry->lock);
-	if (entry->valid && entry->hash == key->hash) { // potential cache hit
-		bpf_spin_unlock(&entry->lock);
-		unsigned int i = 0;
-#pragma clang loop unroll(disable)
-		for (; i < key_len && payload+i+1 <= data_end; i++) { // copy the request key to compare it with the one stored in the cache later
-			key->data[i] = payload[i];
+		if (set_found == 0 && payload[off] == 's' && payload+off+3 <= data_end && payload[off+1] == 'e' && payload[off+2] == 't') {
+			set_found = 1;
+			off += 3; // move offset after the set keywork, at the next iteration 'off' will either point to a space or the start of the key
+			stats->set_recv_count++;
 		}
-		key->len = key_len;
-		pctx->key_count++;
-	} else { // cache miss
-		bpf_spin_unlock(&entry->lock);
-		struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
-		if (!stats) {
-			return XDP_PASS;
+		else if (key_found == 0 && set_found == 1 && payload[off] != ' ') {
+			if (payload[off] == '\r') { // end of packet
+				set_found = 0;
+				key_found = 0;
+			} else { // found the start of the key
+				hash = FNV_OFFSET_BASIS_32;
+				hash ^= payload[off];
+				hash *= FNV_PRIME_32;
+				key_found = 1;
+			}
 		}
-		stats->miss_count++;
-	}
-
-	if (done_parsing) { // the end of the request has been reached
-		bpf_xdp_adjust_head(ctx, 0 - (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header) + pctx->read_pkt_offset)); // pop headers + 'get ' + previous keys
-		if (pctx->key_count > 0) {
-			bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_PREPARE_PACKET);
+		else if (key_found == 1) {
+			if (payload[off] == ' ') { // found the end of the key
+				__u32 cache_idx = hash % BMC_CACHE_ENTRY_COUNT;
+				struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
+				if (!entry) {
+					return XDP_PASS;
+				}
+				bpf_spin_lock(&entry->lock);
+				if (entry->valid) {
+					entry->valid = 0;
+					stats->invalidation_count++;
+				}
+				bpf_spin_unlock(&entry->lock);
+				set_found = 0;
+				key_found = 0;
+			}
+			else { // still processing the key
+				hash ^= payload[off];
+				hash *= FNV_PRIME_32;
+			}
 		}
-	} else { // more keys to process
-		off++; // move offset to the start of the next key
-		pctx->read_pkt_offset += off;
-		if (bpf_xdp_adjust_head(ctx, off)) // push the previous key
-			return XDP_PASS;
-		bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_HASH_KEYS);
 	}
 
 	return XDP_PASS;
 }
 
-SEC("bmc_prepare_packet")
-int bmc_prepare_packet_main(struct xdp_md *ctx)
-{
-	if (bpf_xdp_adjust_head(ctx, -ADJUST_HEAD_LEN)) {
-		// // pop empty packet buffer memory to increase the available packet size
-		bpf_printk("bmc_prepare_packet_main: failed to increase packet size");
-		return XDP_DROP;
-	}
-
-	void *data_end = (void *)(long)ctx->data_end;
-	void *data = (void *)(long)ctx->data;
-	struct ethhdr *eth = data;
-	struct iphdr *ip = data + sizeof(*eth);
-	struct udphdr *udp = data + sizeof(*eth) + sizeof(*ip);
-	struct memcached_udp_header *memcached_udp_hdr = data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp);
-	char *payload = (char *) (memcached_udp_hdr + 1);
-	void *old_data = data + ADJUST_HEAD_LEN;
-	char *old_payload = (char *) (old_data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr));
-
-	if (payload >= data_end || old_payload+1 >= data_end)
-		return XDP_PASS;
-
-	// use old headers as a base; then update addresses and ports to create the new headers
-	memmove(eth, old_data, sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr));
-
-	unsigned char tmp_mac[ETH_ALEN];
-	__be32 tmp_ip;
-	__be16 tmp_port;
-
-	memcpy(tmp_mac, eth->h_source, ETH_ALEN);
-	memcpy(eth->h_source, eth->h_dest, ETH_ALEN);
-	memcpy(eth->h_dest, tmp_mac, ETH_ALEN);
-
-	tmp_ip = ip->saddr;
-	ip->saddr = ip->daddr;
-	ip->daddr = tmp_ip;
-
-	tmp_port = udp->source;
-	udp->source = udp->dest;
-	udp->dest = tmp_port;
-
-	if (bpf_xdp_adjust_head(ctx, sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr))) // push new headers
-		return XDP_PASS;
-
-	bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_WRITE_REPLY);
-
-	return XDP_PASS;
-}
-
-SEC("bmc_write_reply")
-int bmc_write_reply_main(struct xdp_md *ctx)
+static inline int bmc_write_reply_main(struct xdp_md *ctx)
 {
 	void *data_end = (void *)(long)ctx->data_end;
 	void *data = (void *)(long)ctx->data;
@@ -362,7 +217,6 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 
 	bpf_spin_lock(&entry->lock);
 	if (entry->valid && key->hash == entry->hash) { // if saved key still matches its corresponding cache entry
-#pragma clang loop unroll(disable)
 		for (int i = 0; i < BMC_MAX_KEY_LENGTH && i < key->len; i++) { // compare the saved key with the one stored in the cache entry
 			if (key->data[i] != entry->data[6+i]) {
 				cache_hit = 0;
@@ -370,7 +224,6 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 		}
 		if (cache_hit) { // if cache HIT then copy cached data
 			unsigned int off;
-#pragma clang loop unroll(disable)
 			for (off = 0; off+sizeof(unsigned long long) < BMC_MAX_CACHE_DATA_SIZE &&
 					off+sizeof(unsigned long long) <= entry->len &&
 					payload+off+sizeof(unsigned long long) <= data_end; off++) {
@@ -378,7 +231,6 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 				off += sizeof(unsigned long long)-1;
 				written += sizeof(unsigned long long);
 			}
-#pragma clang loop unroll(disable)
 			for (; off < BMC_MAX_CACHE_DATA_SIZE && off < entry->len
 					&& payload+off+1 <= data_end; off++) {
 				payload[off] = entry->data[off];
@@ -440,13 +292,14 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 		bpf_xdp_adjust_head(ctx, ADJUST_HEAD_LEN - (int) (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header))); // pop to the old headers and transmit to netstack
 		return XDP_PASS;
 	} else if (pctx->current_key < BMC_MAX_KEY_IN_PACKET) { // else if there are still keys to process
-		pctx->write_pkt_offset += written; // save packet write offset
-		if (bpf_xdp_adjust_head(ctx, written)) {
-			// push written data
-			bpf_printk("bmc_write_reply_main: failed to resize packet for written response");
-			return XDP_DROP;
-		}
-		bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_WRITE_REPLY);
+		return XDP_ABORTED;
+		/* pctx->write_pkt_offset += written; // save packet write offset */
+		/* if (bpf_xdp_adjust_head(ctx, written)) { */
+		/* 	// push written data */
+		/* 	bpf_printk("bmc_write_reply_main: failed to resize packet for written response"); */
+		/* 	return XDP_DROP; */
+		/* } */
+		/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_WRITE_REPLY); */
 	}
 
 	bpf_printk("bmc_write_reply_main: failed");
@@ -461,68 +314,207 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 	return XDP_DROP;
 }
 
-SEC("bmc_invalidate_cache")
-int bmc_invalidate_cache_main(struct xdp_md *ctx)
+static inline int bmc_prepare_packet_main(struct xdp_md *ctx)
 {
+	if (bpf_xdp_adjust_head(ctx, -ADJUST_HEAD_LEN)) {
+		// // pop empty packet buffer memory to increase the available packet size
+		bpf_printk("bmc_prepare_packet_main: failed to increase packet size");
+		return XDP_DROP;
+	}
+
 	void *data_end = (void *)(long)ctx->data_end;
 	void *data = (void *)(long)ctx->data;
 	struct ethhdr *eth = data;
 	struct iphdr *ip = data + sizeof(*eth);
-	struct tcphdr *tcp = data + sizeof(*eth) + sizeof(*ip);
-	char *payload = (char *) (tcp + 1);
+	struct udphdr *udp = data + sizeof(*eth) + sizeof(*ip);
+	struct memcached_udp_header *memcached_udp_hdr = data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp);
+	char *payload = (char *) (memcached_udp_hdr + 1);
+	void *old_data = data + ADJUST_HEAD_LEN;
+	char *old_payload = (char *) (old_data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr));
+
+	if (payload >= data_end || old_payload+1 >= data_end)
+		return XDP_PASS;
+
+	// use old headers as a base; then update addresses and ports to create the new headers
+	memmove(eth, old_data, sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr));
+
+	unsigned char tmp_mac[ETH_ALEN];
+	__be32 tmp_ip;
+	__be16 tmp_port;
+
+	memcpy(tmp_mac, eth->h_source, ETH_ALEN);
+	memcpy(eth->h_source, eth->h_dest, ETH_ALEN);
+	memcpy(eth->h_dest, tmp_mac, ETH_ALEN);
+
+	tmp_ip = ip->saddr;
+	ip->saddr = ip->daddr;
+	ip->daddr = tmp_ip;
+
+	tmp_port = udp->source;
+	udp->source = udp->dest;
+	udp->dest = tmp_port;
+
+	if (bpf_xdp_adjust_head(ctx, sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr))) // push new headers
+		return XDP_PASS;
+
+	/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_WRITE_REPLY); */
+	return bmc_write_reply_main(ctx);
+	/* return XDP_PASS; */
+}
+
+static inline int bmc_hash_keys_main(struct xdp_md *ctx)
+{
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data = (void *)(long)ctx->data;
+	char *payload = (char *) data;
 	unsigned int zero = 0;
 
 	if (payload >= data_end)
 		return XDP_PASS;
 
-	struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
-	if (!stats) {
+	struct parsing_context *pctx = bpf_map_lookup_elem(&map_parsing_context, &zero);
+	if (!pctx) {
 		return XDP_PASS;
 	}
 
-	__u32 hash;
-	int set_found = 0, key_found = 0;
+	struct memcached_key *key = bpf_map_lookup_elem(&map_keys, &pctx->key_count);
+	if (!key) {
+		return XDP_PASS;
+	}
+	key->hash = FNV_OFFSET_BASIS_32;
 
-#pragma clang loop unroll(disable)
-	for (unsigned int off = 0; off < BMC_MAX_PACKET_LENGTH && payload+off+1 <= data_end; off++) {
+	unsigned int off, done_parsing = 0, key_len = 0;
 
-		if (set_found == 0 && payload[off] == 's' && payload+off+3 <= data_end && payload[off+1] == 'e' && payload[off+2] == 't') {
-			set_found = 1;
-			off += 3; // move offset after the set keywork, at the next iteration 'off' will either point to a space or the start of the key
-			stats->set_recv_count++;
+	// compute the key hash
+	for (off = 0; off < BMC_MAX_KEY_LENGTH+1 && payload+off+1 <= data_end; off++) {
+		if (payload[off] == '\r') {
+			done_parsing = 1;
+			break;
 		}
-		else if (key_found == 0 && set_found == 1 && payload[off] != ' ') {
-			if (payload[off] == '\r') { // end of packet
-				set_found = 0;
-				key_found = 0;
-			} else { // found the start of the key
-				hash = FNV_OFFSET_BASIS_32;
-				hash ^= payload[off];
-				hash *= FNV_PRIME_32;
-				key_found = 1;
-			}
+		else if (payload[off] == ' ') {
+			break;
 		}
-		else if (key_found == 1) {
-			if (payload[off] == ' ') { // found the end of the key
-				__u32 cache_idx = hash % BMC_CACHE_ENTRY_COUNT;
-				struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
-				if (!entry) {
+		else if (payload[off] != ' ') {
+			key->hash ^= payload[off];
+			key->hash *= FNV_PRIME_32;
+			key_len++;
+		}
+	}
+
+	if (key_len == 0 || key_len > BMC_MAX_KEY_LENGTH) {
+		bpf_xdp_adjust_head(ctx, 0 - (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header) + pctx->read_pkt_offset)); // unexpected key, let the netstack handle it
+		return XDP_PASS;
+	}
+
+	__u32 cache_idx = key->hash % BMC_CACHE_ENTRY_COUNT;
+	struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
+	if (!entry) { // should never happen since cache map is of type BPF_MAP_TYPE_ARRAY
+		return XDP_PASS;
+	}
+
+	bpf_spin_lock(&entry->lock);
+	if (entry->valid && entry->hash == key->hash) { // potential cache hit
+		bpf_spin_unlock(&entry->lock);
+		unsigned int i = 0;
+		for (; i < key_len && payload+i+1 <= data_end; i++) { // copy the request key to compare it with the one stored in the cache later
+			key->data[i] = payload[i];
+		}
+		key->len = key_len;
+		pctx->key_count++;
+	} else { // cache miss
+		bpf_spin_unlock(&entry->lock);
+		struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
+		if (!stats) {
+			return XDP_PASS;
+		}
+		stats->miss_count++;
+	}
+
+	if (done_parsing) { // the end of the request has been reached
+		bpf_xdp_adjust_head(ctx, 0 - (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header) + pctx->read_pkt_offset)); // pop headers + 'get ' + previous keys
+		if (pctx->key_count > 0) {
+			/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_PREPARE_PACKET); */
+			return bmc_prepare_packet_main(ctx);
+		}
+	} else { // more keys to process
+		return XDP_ABORTED;
+		/* off++; // move offset to the start of the next key */
+		/* pctx->read_pkt_offset += off; */
+		/* if (bpf_xdp_adjust_head(ctx, off)) // push the previous key */
+		/* 	return XDP_PASS; */
+		/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_HASH_KEYS); */
+	}
+
+	return XDP_PASS;
+}
+
+SEC("bmc_rx_filter")
+int bmc_rx_filter_main(struct xdp_md *ctx)
+{
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data = (void *)(long)ctx->data;
+	struct ethhdr *eth = (struct ethhdr *)data;
+	struct iphdr *ip = (struct iphdr *)((__u8 *)data + sizeof(*eth));
+	void *transp = (__u8 *)data + sizeof(*eth) + sizeof(*ip);
+	struct udphdr *udp;
+	struct tcphdr *tcp;
+	char *payload;
+	__be16 dport;
+
+	if ((void *)(ip + 1) > data_end)
+		return XDP_PASS;
+
+	switch (ip->protocol) {
+		case IPPROTO_UDP:
+			udp = (struct udphdr *) transp;
+			if (udp + 1 > data_end)
+				return XDP_PASS;
+			dport = udp->dest;
+			payload = transp + sizeof(*udp) + sizeof(struct memcached_udp_header);
+			break;
+		case IPPROTO_TCP:
+			tcp = (struct tcphdr *) transp;
+			if (tcp + 1 > data_end)
+				return XDP_PASS;
+			dport = tcp->dest;
+			payload = transp + sizeof(*tcp);
+			break;
+		default:
+			return XDP_PASS;
+	}
+
+	if (dport == bpf_htons(11211) && payload+4 <= data_end) {
+		if (ip->protocol == IPPROTO_UDP && payload[0] == 'g' && payload[1] == 'e' && payload[2] == 't' && payload[3] == ' ') { // is this a GET request
+			unsigned int zero = 0;
+			struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
+			if (!stats) {
+				return XDP_PASS;
+			}
+			stats->get_recv_count++;
+
+			struct parsing_context *pctx = bpf_map_lookup_elem(&map_parsing_context, &zero);
+			if (!pctx) {
+				return XDP_PASS;
+			}
+			pctx->key_count = 0;
+			pctx->current_key = 0;
+			pctx->write_pkt_offset = 0;
+
+			unsigned int off;
+			for (off = 4; off < BMC_MAX_PACKET_LENGTH && payload+off+1 <= data_end && payload[off] == ' '; off++) {} // move offset to the start of the first key
+			if (off < BMC_MAX_PACKET_LENGTH) {
+				pctx->read_pkt_offset = off; // save offset
+				if (bpf_xdp_adjust_head(ctx, (int)(sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(struct memcached_udp_header) + off))) { // push headers + 'get ' keyword
 					return XDP_PASS;
 				}
-				bpf_spin_lock(&entry->lock);
-				if (entry->valid) {
-					entry->valid = 0;
-					stats->invalidation_count++;
-				}
-				bpf_spin_unlock(&entry->lock);
-				set_found = 0;
-				key_found = 0;
-			}
-			else { // still processing the key
-				hash ^= payload[off];
-				hash *= FNV_PRIME_32;
+				/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_HASH_KEYS); */
+				return bmc_hash_keys_main(ctx);
 			}
 		}
+		else if (ip->protocol == IPPROTO_TCP) {
+			/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_INVALIDATE_CACHE); */
+			return bmc_invalidate_cache_main(ctx);
+		}
 	}
 
 	return XDP_PASS;
diff --git a/bmc/bmc_user.c b/bmc/bmc_user.c
index 38d36d6..0d2639d 100644
--- a/bmc/bmc_user.c
+++ b/bmc/bmc_user.c
@@ -43,10 +43,10 @@ struct bpf_progs_desc {
 
 static struct bpf_progs_desc progs[] = {
 	{"bmc_rx_filter", BPF_PROG_TYPE_XDP, 0, -1, NULL},
-	{"bmc_hash_keys", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_HASH_KEYS, NULL},
-	{"bmc_prepare_packet", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_PREPARE_PACKET, NULL},
-	{"bmc_write_reply", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_WRITE_REPLY, NULL},
-	{"bmc_invalidate_cache", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_INVALIDATE_CACHE, NULL},
+	/* {"bmc_hash_keys", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_HASH_KEYS, NULL}, */
+	/* {"bmc_prepare_packet", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_PREPARE_PACKET, NULL}, */
+	/* {"bmc_write_reply", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_WRITE_REPLY, NULL}, */
+	/* {"bmc_invalidate_cache", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_INVALIDATE_CACHE, NULL}, */
 
 	{"bmc_tx_filter", BPF_PROG_TYPE_SCHED_CLS, 1, -1, NULL},
 	{"bmc_update_cache", BPF_PROG_TYPE_SCHED_CLS, 0, BMC_PROG_TC_UPDATE_CACHE, NULL},
-- 
2.34.1

