From 14d47e319c73525fea012057ce2a13f0d9d8bb84 Mon Sep 17 00:00:00 2001
From: Farbod Shahinfar <fshahinfar1@gmail.com>
Date: Mon, 16 Sep 2024 11:06:47 +0000
Subject: [PATCH 2/2] use bpf-2-bpf function call instead of tail calls

---
 bmc/Makefile   |   9 +-
 bmc/bmc_kern.c | 602 +++++++++++++++++++++++++------------------------
 bmc/bmc_user.c |  10 +-
 bmc/run.sh     |  30 +++
 4 files changed, 355 insertions(+), 296 deletions(-)
 create mode 100755 bmc/run.sh

diff --git a/bmc/Makefile b/bmc/Makefile
index 6b6a8ec..8438894 100644
--- a/bmc/Makefile
+++ b/bmc/Makefile
@@ -3,11 +3,18 @@ BPF_COMPILE_SCRIPT=$(BPF_GEN_DIR)/compile_scripts/compile_bpf_source.sh
 
 BPF_CFLAGS =
 
+.PHONY: default clean
+
 default: bmc_kern.o bmc
 
+clean:
+	rm bmc bmc_kern.o
+
 bmc_kern.o: bmc_kern.c bmc_common.h
 	export CFLAGS="$(BPF_CFLAGS)" && bash $(BPF_COMPILE_SCRIPT) bmc_kern.c $@
 
+OLD_LIBBPF_HEADER=$(HOME)/old_libbpf/src/build/usr/include/
+OLD_LIBBPF_LIB=$(HOME)/old_libbpf/src/build/usr/lib64/
 bmc: bmc_user.c bmc_common.h
-	gcc -O2 -g -Wall -o $@ bmc_user.c -lbpf -lelf -lz -lpthread
+	gcc -O2 -g -Wall -I $(OLD_LIBBPF_HEADER) -o $@ bmc_user.c -L$(OLD_LIBBPF_LIB)  -lbpf  -lelf -lz -lpthread
 
diff --git a/bmc/bmc_kern.c b/bmc/bmc_kern.c
index c05a616..a52bf34 100644
--- a/bmc/bmc_kern.c
+++ b/bmc/bmc_kern.c
@@ -76,35 +76,35 @@ struct parsing_context {
 	unsigned short read_pkt_offset;
 	unsigned short write_pkt_offset;
 };
-struct bpf_map_def SEC("maps") map_parsing_context = {
-	.type = BPF_MAP_TYPE_PERCPU_ARRAY,
-	.key_size = sizeof(unsigned int),
-	.value_size = sizeof(struct parsing_context),
-	.max_entries = 1,
-};
+struct {
+	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+	__type(key, unsigned int);
+	__type(value,struct parsing_context);
+	__uint(max_entries, 1);
+} map_parsing_context SEC(".maps");
 
 /* stats */
-struct bpf_map_def SEC("maps") map_stats = {
-	.type = BPF_MAP_TYPE_PERCPU_ARRAY,
-	.key_size = sizeof(unsigned int),
-	.value_size = sizeof(struct bmc_stats),
-	.max_entries = 1,
-};
+struct {
+	__uint(type, BPF_MAP_TYPE_PERCPU_ARRAY);
+	__type(key, unsigned int);
+	__type(value, struct bmc_stats);
+	__uint(max_entries, 1);
+} map_stats SEC(".maps");
 
 /* program maps */
-struct bpf_map_def SEC("maps") map_progs_xdp = {
-	.type = BPF_MAP_TYPE_PROG_ARRAY,
-	.key_size = sizeof(__u32),
-	.value_size = sizeof(__u32),
-	.max_entries = BMC_PROG_XDP_MAX,
-};
+struct {
+	__uint(type, BPF_MAP_TYPE_PROG_ARRAY);
+	__type(key, __u32);
+	__type(value, __u32);
+	__uint(max_entries, BMC_PROG_XDP_MAX);
+} map_progs_xdp SEC(".maps");
 
-struct bpf_map_def SEC("maps") map_progs_tc = {
-	.type = BPF_MAP_TYPE_PROG_ARRAY,
-	.key_size = sizeof(__u32),
-	.value_size = sizeof(__u32),
-	.max_entries = BMC_PROG_TC_MAX,
-};
+struct {
+	__uint(type , BPF_MAP_TYPE_PROG_ARRAY);
+	__type(key , __u32);
+	__type(value , __u32);
+	__uint(max_entries , BMC_PROG_TC_MAX);
+} map_progs_tc SEC(".maps");
 
 
 static inline __u16 compute_ip_checksum(struct iphdr *ip)
@@ -122,217 +122,78 @@ static inline __u16 compute_ip_checksum(struct iphdr *ip)
 	return ~((csum & 0xffff) + (csum >> 16));
 }
 
-SEC("bmc_rx_filter")
-int bmc_rx_filter_main(struct xdp_md *ctx)
+#define noinline __attribute__((noinline))
+
+/* SEC("bmc_invalidate_cache") */
+static noinline int bmc_invalidate_cache_main(struct xdp_md *ctx)
 {
 	void *data_end = (void *)(long)ctx->data_end;
 	void *data = (void *)(long)ctx->data;
 	struct ethhdr *eth = data;
 	struct iphdr *ip = data + sizeof(*eth);
-	void *transp = data + sizeof(*eth) + sizeof(*ip);
-	struct udphdr *udp;
-	struct tcphdr *tcp;
-	char *payload;
-	__be16 dport;
-
-	if (ip + 1 > data_end)
-		return XDP_PASS;
-
-	switch (ip->protocol) {
-		case IPPROTO_UDP:
-			udp = (struct udphdr *) transp;
-			if (udp + 1 > data_end)
-				return XDP_PASS;
-			dport = udp->dest;
-			payload = transp + sizeof(*udp) + sizeof(struct memcached_udp_header);
-			break;
-		case IPPROTO_TCP:
-			tcp = (struct tcphdr *) transp;
-			if (tcp + 1 > data_end)
-				return XDP_PASS;
-			dport = tcp->dest;
-			payload = transp + sizeof(*tcp);
-			break;
-		default:
-			return XDP_PASS;
-	}
-
-	if (dport == bpf_htons(11211) && payload+4 <= data_end) {
-
-		if (ip->protocol == IPPROTO_UDP && payload[0] == 'g' && payload[1] == 'e' && payload[2] == 't' && payload[3] == ' ') { // is this a GET request
-			unsigned int zero = 0;
-			struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
-			if (!stats) {
-				return XDP_PASS;
-			}
-			stats->get_recv_count++;
-
-			struct parsing_context *pctx = bpf_map_lookup_elem(&map_parsing_context, &zero);
-			if (!pctx) {
-				return XDP_PASS;
-			}
-			pctx->key_count = 0;
-			pctx->current_key = 0;
-			pctx->write_pkt_offset = 0;
-
-			unsigned int off;
-#pragma clang loop unroll(disable)
-			for (off = 4; off < BMC_MAX_PACKET_LENGTH && payload+off+1 <= data_end && payload[off] == ' '; off++) {} // move offset to the start of the first key
-			if (off < BMC_MAX_PACKET_LENGTH) {
-				pctx->read_pkt_offset = off; // save offset
-				if (bpf_xdp_adjust_head(ctx, (int)(sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(struct memcached_udp_header) + off))) { // push headers + 'get ' keyword
-					return XDP_PASS;
-				}
-				bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_HASH_KEYS);
-			}
-		}
-		else if (ip->protocol == IPPROTO_TCP) {
-			bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_INVALIDATE_CACHE);
-		}
-	}
-
-	return XDP_PASS;
-}
-
-
-SEC("bmc_hash_keys")
-int bmc_hash_keys_main(struct xdp_md *ctx)
-{
-	void *data_end = (void *)(long)ctx->data_end;
-	void *data = (void *)(long)ctx->data;
-	char *payload = (char *) data;
+	struct tcphdr *tcp = data + sizeof(*eth) + sizeof(*ip);
+	char *payload = (char *) (tcp + 1);
 	unsigned int zero = 0;
 
 	if (payload >= data_end)
 		return XDP_PASS;
 
-	struct parsing_context *pctx = bpf_map_lookup_elem(&map_parsing_context, &zero);
-	if (!pctx) {
-		return XDP_PASS;
-	}
-
-	struct memcached_key *key = bpf_map_lookup_elem(&map_keys, &pctx->key_count);
-	if (!key) {
+	struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
+	if (!stats) {
 		return XDP_PASS;
 	}
-	key->hash = FNV_OFFSET_BASIS_32;
 
-	unsigned int off, done_parsing = 0, key_len = 0;
+	__u32 hash;
+	int set_found = 0, key_found = 0;
 
-	// compute the key hash
 #pragma clang loop unroll(disable)
-	for (off = 0; off < BMC_MAX_KEY_LENGTH+1 && payload+off+1 <= data_end; off++) {
-		if (payload[off] == '\r') {
-			done_parsing = 1;
-			break;
-		}
-		else if (payload[off] == ' ') {
-			break;
-		}
-		else if (payload[off] != ' ') {
-			key->hash ^= payload[off];
-			key->hash *= FNV_PRIME_32;
-			key_len++;
-		}
-	}
-
-	if (key_len == 0 || key_len > BMC_MAX_KEY_LENGTH) {
-		bpf_xdp_adjust_head(ctx, 0 - (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header) + pctx->read_pkt_offset)); // unexpected key, let the netstack handle it
-		return XDP_PASS;
-	}
-
-	__u32 cache_idx = key->hash % BMC_CACHE_ENTRY_COUNT;
-	struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
-	if (!entry) { // should never happen since cache map is of type BPF_MAP_TYPE_ARRAY
-		return XDP_PASS;
-	}
+	for (unsigned int off = 0; off < BMC_MAX_PACKET_LENGTH && payload+off+1 <= data_end; off++) {
 
-	bpf_spin_lock(&entry->lock);
-	if (entry->valid && entry->hash == key->hash) { // potential cache hit
-		bpf_spin_unlock(&entry->lock);
-		unsigned int i = 0;
-#pragma clang loop unroll(disable)
-		for (; i < key_len && payload+i+1 <= data_end; i++) { // copy the request key to compare it with the one stored in the cache later
-			key->data[i] = payload[i];
+		if (set_found == 0 && payload[off] == 's' && payload+off+3 <= data_end && payload[off+1] == 'e' && payload[off+2] == 't') {
+			set_found = 1;
+			off += 3; // move offset after the set keywork, at the next iteration 'off' will either point to a space or the start of the key
+			stats->set_recv_count++;
 		}
-		key->len = key_len;
-		pctx->key_count++;
-	} else { // cache miss
-		bpf_spin_unlock(&entry->lock);
-		struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
-		if (!stats) {
-			return XDP_PASS;
+		else if (key_found == 0 && set_found == 1 && payload[off] != ' ') {
+			if (payload[off] == '\r') { // end of packet
+				set_found = 0;
+				key_found = 0;
+			} else { // found the start of the key
+				hash = FNV_OFFSET_BASIS_32;
+				hash ^= payload[off];
+				hash *= FNV_PRIME_32;
+				key_found = 1;
+			}
 		}
-		stats->miss_count++;
-	}
-
-	if (done_parsing) { // the end of the request has been reached
-		bpf_xdp_adjust_head(ctx, 0 - (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header) + pctx->read_pkt_offset)); // pop headers + 'get ' + previous keys
-		if (pctx->key_count > 0) {
-			bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_PREPARE_PACKET);
+		else if (key_found == 1) {
+			if (payload[off] == ' ') { // found the end of the key
+				__u32 cache_idx = hash % BMC_CACHE_ENTRY_COUNT;
+				struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
+				if (!entry) {
+					return XDP_PASS;
+				}
+				bpf_spin_lock(&entry->lock);
+				if (entry->valid) {
+					entry->valid = 0;
+					stats->invalidation_count++;
+				}
+				bpf_spin_unlock(&entry->lock);
+				set_found = 0;
+				key_found = 0;
+			}
+			else { // still processing the key
+				hash ^= payload[off];
+				hash *= FNV_PRIME_32;
+			}
 		}
-	} else { // more keys to process
-		off++; // move offset to the start of the next key
-		pctx->read_pkt_offset += off;
-		if (bpf_xdp_adjust_head(ctx, off)) // push the previous key
-			return XDP_PASS;
-		bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_HASH_KEYS);
 	}
 
 	return XDP_PASS;
 }
 
-SEC("bmc_prepare_packet")
-int bmc_prepare_packet_main(struct xdp_md *ctx)
-{
-	if (bpf_xdp_adjust_head(ctx, -ADJUST_HEAD_LEN)) {
-		// // pop empty packet buffer memory to increase the available packet size
-		bpf_printk("bmc_prepare_packet_main: failed to increase packet size");
-		return XDP_DROP;
-	}
-
-	void *data_end = (void *)(long)ctx->data_end;
-	void *data = (void *)(long)ctx->data;
-	struct ethhdr *eth = data;
-	struct iphdr *ip = data + sizeof(*eth);
-	struct udphdr *udp = data + sizeof(*eth) + sizeof(*ip);
-	struct memcached_udp_header *memcached_udp_hdr = data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp);
-	char *payload = (char *) (memcached_udp_hdr + 1);
-	void *old_data = data + ADJUST_HEAD_LEN;
-	char *old_payload = (char *) (old_data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr));
-
-	if (payload >= data_end || old_payload+1 >= data_end)
-		return XDP_PASS;
-
-	// use old headers as a base; then update addresses and ports to create the new headers
-	memmove(eth, old_data, sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr));
-
-	unsigned char tmp_mac[ETH_ALEN];
-	__be32 tmp_ip;
-	__be16 tmp_port;
-
-	memcpy(tmp_mac, eth->h_source, ETH_ALEN);
-	memcpy(eth->h_source, eth->h_dest, ETH_ALEN);
-	memcpy(eth->h_dest, tmp_mac, ETH_ALEN);
-
-	tmp_ip = ip->saddr;
-	ip->saddr = ip->daddr;
-	ip->daddr = tmp_ip;
 
-	tmp_port = udp->source;
-	udp->source = udp->dest;
-	udp->dest = tmp_port;
-
-	if (bpf_xdp_adjust_head(ctx, sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr))) // push new headers
-		return XDP_PASS;
-
-	bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_WRITE_REPLY);
-
-	return XDP_PASS;
-}
-
-SEC("bmc_write_reply")
-int bmc_write_reply_main(struct xdp_md *ctx)
+/* SEC("bmc_write_reply") */
+static noinline int bmc_write_reply_main(struct xdp_md *ctx)
 {
 	void *data_end = (void *)(long)ctx->data_end;
 	void *data = (void *)(long)ctx->data;
@@ -356,7 +217,7 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 	__u32 cache_idx = key->hash % BMC_CACHE_ENTRY_COUNT;
 	struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
 	if (!entry) {
-		bpf_printk("bmc_write_reply_main: cache entry not found!");
+		/* bpf_printk("_bmc_write_reply_main: cache entry not found!"); */
 		return XDP_DROP;
 	}
 
@@ -413,7 +274,7 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 			if (bpf_xdp_adjust_head(ctx, 0 - (int) (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr)
 													+ sizeof(struct memcached_udp_header) + pctx->write_pkt_offset))) {
 				// pop headers + previously written data
-				bpf_printk("bmc_write_reply_main: failed to resize the packet");
+				/* bpf_printk("_bmc_write_reply_main: failed to resize the packet"); */
 				return XDP_DROP;
 			}
 
@@ -423,8 +284,10 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 			struct udphdr *udp = data + sizeof(struct ethhdr) + sizeof(*ip);
 			payload = data + sizeof(struct ethhdr) + sizeof(*ip) + sizeof(*udp) + sizeof(struct memcached_udp_header);
 
-			if (udp + 1 > data_end)
+			if (udp + 1 > data_end) {
+				/* bpf_printk("unexpcted and wrong!"); */
 				return XDP_PASS;
+			}
 
 			ip->tot_len = bpf_htons((payload+pctx->write_pkt_offset+written) - (char*)ip);
 			ip->check = compute_ip_checksum(ip);
@@ -436,141 +299,259 @@ int bmc_write_reply_main(struct xdp_md *ctx)
 			return XDP_TX;
 		}
 	} else if (pctx->current_key == pctx->key_count) { // else if all saved keys have been processed but got no cache HIT; either because of a hash colision or a race with a cache update
+		/* bpf_printk("this must not happen (write reply but no hit?)"); */
 		stats->hit_misprediction += pctx->key_count;
 		bpf_xdp_adjust_head(ctx, ADJUST_HEAD_LEN - (int) (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header))); // pop to the old headers and transmit to netstack
 		return XDP_PASS;
 	} else if (pctx->current_key < BMC_MAX_KEY_IN_PACKET) { // else if there are still keys to process
+		/* bpf_printk("multiple keys 1"); */
 		pctx->write_pkt_offset += written; // save packet write offset
 		if (bpf_xdp_adjust_head(ctx, written)) {
 			// push written data
-			bpf_printk("bmc_write_reply_main: failed to resize packet for written response");
+			/* bpf_printk("_bmc_write_reply_main: failed to resize packet for written response"); */
 			return XDP_DROP;
 		}
-		bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_WRITE_REPLY);
+		/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_WRITE_REPLY); */
+		/* bmc_write_reply_main(ctx); */
+		return XDP_ABORTED;
 	}
 
-	bpf_printk("bmc_write_reply_main: failed");
+	/* bpf_printk("_bmc_write_reply_main: failed"); */
 	/* bpf_printk("current_key: %d/%d (max: %d)", pctx->current_key, pctx->key_count, BMC_MAX_KEY_IN_PACKET); */
-	bpf_printk("written data: %d", written);
+	/* bpf_printk("written data: %d", written); */
 
 	/* void *x = payload+written+5; */
 	/* void *y = data_end; */
 	/* bpf_printk("%p >? %p = %d",  x, y, x > y); */
-	__u16 tmp_size = (__u16)(__u64)(data_end - data);
-	bpf_printk("packet size: %d", tmp_size);
+	/* __u16 tmp_size = (__u16)(__u64)(data_end - data); */
+	/* bpf_printk("packet size: %d", tmp_size); */
 	return XDP_DROP;
 }
 
-SEC("bmc_invalidate_cache")
-int bmc_invalidate_cache_main(struct xdp_md *ctx)
+/* SEC("bmc_prepare_packet") */
+static noinline int bmc_prepare_packet_main(struct xdp_md *ctx)
 {
+	if (bpf_xdp_adjust_head(ctx, -ADJUST_HEAD_LEN)) {
+		// // pop empty packet buffer memory to increase the available packet size
+		/* bpf_printk("bmc_prepare_packet_main: failed to increase packet size"); */
+		return XDP_DROP;
+	}
+
 	void *data_end = (void *)(long)ctx->data_end;
 	void *data = (void *)(long)ctx->data;
 	struct ethhdr *eth = data;
 	struct iphdr *ip = data + sizeof(*eth);
-	struct tcphdr *tcp = data + sizeof(*eth) + sizeof(*ip);
-	char *payload = (char *) (tcp + 1);
+	struct udphdr *udp = data + sizeof(*eth) + sizeof(*ip);
+	struct memcached_udp_header *memcached_udp_hdr = data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp);
+	char *payload = (char *) (memcached_udp_hdr + 1);
+	void *old_data = data + ADJUST_HEAD_LEN;
+	char *old_payload = (char *) (old_data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr));
+
+	if (payload >= data_end || old_payload+1 >= data_end) {
+		/* bpf_printk("wierd out of range ?"); */
+		return XDP_PASS;
+	}
+
+
+	// use old headers as a base; then update addresses and ports to create the new headers
+	memmove(eth, old_data, sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr));
+
+	unsigned char tmp_mac[ETH_ALEN];
+	__be32 tmp_ip;
+	__be16 tmp_port;
+
+	memcpy(tmp_mac, eth->h_source, ETH_ALEN);
+	memcpy(eth->h_source, eth->h_dest, ETH_ALEN);
+	memcpy(eth->h_dest, tmp_mac, ETH_ALEN);
+
+	tmp_ip = ip->saddr;
+	ip->saddr = ip->daddr;
+	ip->daddr = tmp_ip;
+
+	tmp_port = udp->source;
+	udp->source = udp->dest;
+	udp->dest = tmp_port;
+
+	if (bpf_xdp_adjust_head(ctx, sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(*memcached_udp_hdr))) {// push new headers
+		/* bpf_printk("filaed to adjust head! (prepare packet!)"); */
+		return XDP_PASS;
+	}
+
+	/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_WRITE_REPLY); */
+	return bmc_write_reply_main(ctx);
+
+	/* return XDP_PASS; */
+}
+
+/* SEC("bmc_hash_keys") */
+static noinline int bmc_hash_keys_main(struct xdp_md *ctx)
+{
+
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data = (void *)(long)ctx->data;
+	char *payload = (char *) data;
 	unsigned int zero = 0;
 
-	if (payload >= data_end)
+	if ((void *)(payload) >= data_end)
 		return XDP_PASS;
 
-	struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
-	if (!stats) {
+	struct parsing_context *pctx = bpf_map_lookup_elem(&map_parsing_context, &zero);
+	if (!pctx) {
 		return XDP_PASS;
 	}
 
-	__u32 hash;
-	int set_found = 0, key_found = 0;
+	struct memcached_key *key = bpf_map_lookup_elem(&map_keys, &pctx->key_count);
+	if (!key) {
+		return XDP_PASS;
+	}
+	key->hash = FNV_OFFSET_BASIS_32;
+
+	unsigned int off, done_parsing = 0, key_len = 0;
 
+	// compute the key hash
 #pragma clang loop unroll(disable)
-	for (unsigned int off = 0; off < BMC_MAX_PACKET_LENGTH && payload+off+1 <= data_end; off++) {
+	for (off = 0; off < BMC_MAX_KEY_LENGTH+1 && (void *)(payload+off+1) <= data_end; off++) {
+		if (payload[off] == '\r') {
+			done_parsing = 1;
+			break;
+		}
+		else if (payload[off] == ' ') {
+			break;
+		}
+		else if (payload[off] != ' ') {
+			key->hash ^= payload[off];
+			key->hash *= FNV_PRIME_32;
+			key_len++;
+		}
+	}
 
-		if (set_found == 0 && payload[off] == 's' && payload+off+3 <= data_end && payload[off+1] == 'e' && payload[off+2] == 't') {
-			set_found = 1;
-			off += 3; // move offset after the set keywork, at the next iteration 'off' will either point to a space or the start of the key
-			stats->set_recv_count++;
+	if (key_len == 0 || key_len > BMC_MAX_KEY_LENGTH) {
+		/* bpf_printk("unexpected key length!"); */
+		bpf_xdp_adjust_head(ctx, 0 - (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header) + pctx->read_pkt_offset)); // unexpected key, let the netstack handle it
+		return XDP_PASS;
+	}
+
+	__u32 cache_idx = key->hash % BMC_CACHE_ENTRY_COUNT;
+	struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
+	if (!entry) { // should never happen since cache map is of type BPF_MAP_TYPE_ARRAY
+		return XDP_PASS;
+	}
+
+	bpf_spin_lock(&entry->lock);
+	if (entry->valid && entry->hash == key->hash) { // potential cache hit
+		bpf_spin_unlock(&entry->lock);
+		unsigned int i = 0;
+#pragma clang loop unroll(disable)
+		for (; i < key_len && payload+i+1 <= data_end; i++) { // copy the request key to compare it with the one stored in the cache later
+			key->data[i] = payload[i];
 		}
-		else if (key_found == 0 && set_found == 1 && payload[off] != ' ') {
-			if (payload[off] == '\r') { // end of packet
-				set_found = 0;
-				key_found = 0;
-			} else { // found the start of the key
-				hash = FNV_OFFSET_BASIS_32;
-				hash ^= payload[off];
-				hash *= FNV_PRIME_32;
-				key_found = 1;
-			}
+		key->len = key_len;
+		pctx->key_count++;
+	} else { // cache miss
+		bpf_spin_unlock(&entry->lock);
+		struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
+		if (!stats) {
+			return XDP_PASS;
 		}
-		else if (key_found == 1) {
-			if (payload[off] == ' ') { // found the end of the key
-				__u32 cache_idx = hash % BMC_CACHE_ENTRY_COUNT;
-				struct bmc_cache_entry *entry = bpf_map_lookup_elem(&map_kcache, &cache_idx);
-				if (!entry) {
-					return XDP_PASS;
-				}
-				bpf_spin_lock(&entry->lock);
-				if (entry->valid) {
-					entry->valid = 0;
-					stats->invalidation_count++;
-				}
-				bpf_spin_unlock(&entry->lock);
-				set_found = 0;
-				key_found = 0;
-			}
-			else { // still processing the key
-				hash ^= payload[off];
-				hash *= FNV_PRIME_32;
-			}
+		stats->miss_count++;
+	}
+
+	if (done_parsing) { // the end of the request has been reached
+		bpf_xdp_adjust_head(ctx, 0 - (sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header) + pctx->read_pkt_offset)); // pop headers + 'get ' + previous keys
+		if (pctx->key_count > 0) {
+			/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_PREPARE_PACKET); */
+			return bmc_prepare_packet_main(ctx);
 		}
+	} else { // more keys to process
+		/* bpf_printk("multiple keys 2"); */
+		off++; // move offset to the start of the next key
+		pctx->read_pkt_offset += off;
+		if (bpf_xdp_adjust_head(ctx, off)) // push the previous key
+			return XDP_PASS;
+		/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_HASH_KEYS); */
+		/* bmc_hash_keys_main(ctx); */
+		return XDP_ABORTED;
 	}
 
 	return XDP_PASS;
 }
 
-SEC("bmc_tx_filter")
-int bmc_tx_filter_main(struct __sk_buff *skb)
+SEC("bmc_rx_filter")
+int bmc_rx_filter_main(struct xdp_md *ctx)
 {
-	void *data_end = (void *)(long)skb->data_end;
-	void *data     = (void *)(long)skb->data;
+	void *data_end = (void *)(long)ctx->data_end;
+	void *data = (void *)(long)ctx->data;
 	struct ethhdr *eth = data;
 	struct iphdr *ip = data + sizeof(*eth);
-	struct udphdr *udp = data + sizeof(*eth) + sizeof(*ip);
-	char *payload = data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(struct memcached_udp_header);
-	unsigned int zero = 0;
-
-	// if the size exceeds the size of a cache entry do not bother going further
-	if (skb->len > BMC_MAX_CACHE_DATA_SIZE + sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header))
-		return TC_ACT_OK;
+	void *transp = data + sizeof(*eth) + sizeof(*ip);
+	struct udphdr *udp;
+	struct tcphdr *tcp;
+	char *payload;
+	__be16 dport;
 
 	if (ip + 1 > data_end)
 		return XDP_PASS;
 
-	if (ip->protocol != IPPROTO_UDP)
-		return TC_ACT_OK;
+	switch (ip->protocol) {
+		case IPPROTO_UDP:
+			udp = (struct udphdr *) transp;
+			if (udp + 1 > data_end)
+				return XDP_PASS;
+			dport = udp->dest;
+			payload = transp + sizeof(*udp) + sizeof(struct memcached_udp_header);
+			break;
+		case IPPROTO_TCP:
+			tcp = (struct tcphdr *) transp;
+			if (tcp + 1 > data_end)
+				return XDP_PASS;
+			dport = tcp->dest;
+			payload = transp + sizeof(*tcp);
+			break;
+		default:
+			return XDP_PASS;
+	}
 
-	if (udp + 1 > data_end)
-		return TC_ACT_OK;
+	if (dport == bpf_htons(11211) && payload+4 <= data_end) {
 
-	__be16 sport = udp->source;
+		if (ip->protocol == IPPROTO_UDP && payload[0] == 'g' && payload[1] == 'e' && payload[2] == 't' && payload[3] == ' ') { // is this a GET request
+			unsigned int zero = 0;
+			struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
+			if (!stats) {
+				return XDP_PASS;
+			}
+			stats->get_recv_count++;
 
-	if (sport == bpf_htons(11211) && payload+5+1 <= data_end && payload[0] == 'V' && payload[1] == 'A' && payload[2] == 'L'
-		&& payload[3] == 'U' && payload[4] == 'E' && payload[5] == ' ') { // if this is a GET reply
+			struct parsing_context *pctx = bpf_map_lookup_elem(&map_parsing_context, &zero);
+			if (!pctx) {
+				return XDP_PASS;
+			}
+			pctx->key_count = 0;
+			pctx->current_key = 0;
+			pctx->write_pkt_offset = 0;
 
-		struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
-		if (!stats) {
-			return XDP_PASS;
+			unsigned int off;
+#pragma clang loop unroll(disable)
+			for (off = 4; off < BMC_MAX_PACKET_LENGTH && payload+off+1 <= data_end && payload[off] == ' '; off++) {} // move offset to the start of the first key
+			if (off < BMC_MAX_PACKET_LENGTH) {
+				pctx->read_pkt_offset = off; // save offset
+				if (bpf_xdp_adjust_head(ctx, (int)(sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(struct memcached_udp_header) + off))) { // push headers + 'get ' keyword
+					return XDP_PASS;
+				}
+				/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_HASH_KEYS); */
+				return bmc_hash_keys_main(ctx);
+			}
+		}
+		else if (ip->protocol == IPPROTO_TCP) {
+			/* bpf_tail_call(ctx, &map_progs_xdp, BMC_PROG_XDP_INVALIDATE_CACHE); */
+			return bmc_invalidate_cache_main(ctx);
 		}
-		stats->get_resp_count++;
-
-		bpf_tail_call(skb, &map_progs_tc, BMC_PROG_TC_UPDATE_CACHE);
 	}
 
-	return TC_ACT_OK;
+	return XDP_PASS;
 }
 
-SEC("bmc_update_cache")
-int bmc_update_cache_main(struct __sk_buff *skb)
+/* SEC("bmc_update_cache") */
+static int bmc_update_cache_main(struct __sk_buff *skb)
 {
 	void *data_end = (void *)(long)skb->data_end;
 	void *data = (void *)(long)skb->data;
@@ -636,5 +617,46 @@ int bmc_update_cache_main(struct __sk_buff *skb)
 	return TC_ACT_OK;
 }
 
+SEC("bmc_tx_filter")
+int bmc_tx_filter_main(struct __sk_buff *skb)
+{
+	void *data_end = (void *)(long)skb->data_end;
+	void *data     = (void *)(long)skb->data;
+	struct ethhdr *eth = data;
+	struct iphdr *ip = data + sizeof(*eth);
+	struct udphdr *udp = data + sizeof(*eth) + sizeof(*ip);
+	char *payload = data + sizeof(*eth) + sizeof(*ip) + sizeof(*udp) + sizeof(struct memcached_udp_header);
+	unsigned int zero = 0;
+
+	// if the size exceeds the size of a cache entry do not bother going further
+	if (skb->len > BMC_MAX_CACHE_DATA_SIZE + sizeof(struct ethhdr) + sizeof(struct iphdr) + sizeof(struct udphdr) + sizeof(struct memcached_udp_header))
+		return TC_ACT_OK;
+
+	if (ip + 1 > data_end)
+		return XDP_PASS;
+
+	if (ip->protocol != IPPROTO_UDP)
+		return TC_ACT_OK;
+
+	if (udp + 1 > data_end)
+		return TC_ACT_OK;
+
+	__be16 sport = udp->source;
+
+	if (sport == bpf_htons(11211) && payload+5+1 <= data_end && payload[0] == 'V' && payload[1] == 'A' && payload[2] == 'L'
+		&& payload[3] == 'U' && payload[4] == 'E' && payload[5] == ' ') { // if this is a GET reply
+		struct bmc_stats *stats = bpf_map_lookup_elem(&map_stats, &zero);
+		if (!stats) {
+			return XDP_PASS;
+		}
+		stats->get_resp_count++;
+
+		/* bpf_tail_call(skb, &map_progs_tc, BMC_PROG_TC_UPDATE_CACHE); */
+		bmc_update_cache_main(skb);
+	}
+
+	return TC_ACT_OK;
+}
+
 char _license[] SEC("license") = "GPL";
 // to test colisions: keys declinate0123456 and macallums0123456 have hash colision
diff --git a/bmc/bmc_user.c b/bmc/bmc_user.c
index 38d36d6..aae2f5d 100644
--- a/bmc/bmc_user.c
+++ b/bmc/bmc_user.c
@@ -43,13 +43,13 @@ struct bpf_progs_desc {
 
 static struct bpf_progs_desc progs[] = {
 	{"bmc_rx_filter", BPF_PROG_TYPE_XDP, 0, -1, NULL},
-	{"bmc_hash_keys", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_HASH_KEYS, NULL},
-	{"bmc_prepare_packet", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_PREPARE_PACKET, NULL},
-	{"bmc_write_reply", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_WRITE_REPLY, NULL},
-	{"bmc_invalidate_cache", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_INVALIDATE_CACHE, NULL},
+	/* {"bmc_hash_keys", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_HASH_KEYS, NULL}, */
+	/* {"bmc_prepare_packet", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_PREPARE_PACKET, NULL}, */
+	/* {"bmc_write_reply", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_WRITE_REPLY, NULL}, */
+	/* {"bmc_invalidate_cache", BPF_PROG_TYPE_XDP, 0, BMC_PROG_XDP_INVALIDATE_CACHE, NULL}, */
 
 	{"bmc_tx_filter", BPF_PROG_TYPE_SCHED_CLS, 1, -1, NULL},
-	{"bmc_update_cache", BPF_PROG_TYPE_SCHED_CLS, 0, BMC_PROG_TC_UPDATE_CACHE, NULL},
+	/* {"bmc_update_cache", BPF_PROG_TYPE_SCHED_CLS, 0, BMC_PROG_TC_UPDATE_CACHE, NULL}, */
 };
 
 uint32_t fnv1a_hash32(char *key, size_t length, uint32_t hash)
diff --git a/bmc/run.sh b/bmc/run.sh
new file mode 100755
index 0000000..673fa70
--- /dev/null
+++ b/bmc/run.sh
@@ -0,0 +1,30 @@
+#! /bin/bash
+BMC_BIN=./bmc
+if [ -z "$NET_IFACE" ]; then
+        echo "NET_IFACE has not been set"
+        exit 1
+fi
+IFINDEX=$(ip -j addr show $NET_IFACE | jq '.[0].ifindex')
+
+echo Running BMC ...
+$(nohup sudo $BMC_BIN $IFINDEX) &
+sleep 3
+if [ ! -f /sys/fs/bpf/bmc_tx_filter ]; then
+	echo there is something wrong!
+	exit 1
+fi
+
+sudo tc qdisc add dev $NET_IFACE clsact
+sudo tc filter add dev $NET_IFACE egress bpf object-pinned /sys/fs/bpf/bmc_tx_filter
+
+quit=0
+echo "Ctrl-C to stop..."
+while [ $quit -ne 1 ]; do
+    sleep 1
+done
+
+# Detach BMC
+sudo pkill -SIGINT bmc
+sudo tc filter del dev $NET_IFACE egress
+sudo tc qdisc del dev $NET_IFACE clsact
+sudo rm /sys/fs/bpf/bmc_tx_filter
-- 
2.34.1

